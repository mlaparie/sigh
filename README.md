# worldevents (`we`)

Script to scrap, save and print event data from rsoe-edis.org, per event category.

## Installation
#### Dependencies
- `bs4`
- `requests`
- `json`
- `jello`
- `jtbl`

Those are Python dependencies for the autogenerated `.py` scripts, they can be installed with `pip3 install bs4 requests json jello jtbl`

#### Generate scripts

```bash
git clone https://git.teknik.io/matf/worldevents
cd worldevents
./we --setup
ln -s we $HOME/.local/bin/we # Optional, to make `we` accessible from anywhere
```

You may re-generate the `.py` scripts using `we --setup` every time `setup/codes.txt` is manually updated.
Automatically updating codes is not supported yet.

## Usage
```

```
#### Example for floods (code FLD):

```bash
we --get fld
we --print fld
```

## To do
- [ ] Automate scrapping event codes into `setup/codes.txt`
- [ ] Add an option to scrap all categories at once instead of putting strain on the website with a request for every event category
- [ ] Implement `-t`
- [ ] Human readable categories, not only codes
- [ ] Better appending (avoid duplicates, add request date, merge into same json objects instead of creating new ones)
- [X] Make functions into a master script that would generate scripts, clear scripts,show data, delete data, and hopefully fetch codes in case of new categories available (latter part not done yet)

## Disclaimer
Credits to aetin. I was just reading about the `gemini` protocol and testing it with the cool `amfora` client, then stumbled upon `gemini://aetin.art/earth.gmi` and found the concept pretty cool, so I started playing with it. I am not a programmer, and I don't know how to write Python, so don't set your expectations too high.

This is merely a way for me to play with web-scraping and Python for something I find useful, but I am not responsible for what you may use this for. Please just don't abuse using the scrap scripts so that rsoe-edis.org doesn't start adding reCaptchas to their website.
